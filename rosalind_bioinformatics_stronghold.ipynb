{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rosalind - Bioinformatics Stronghold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_FASTA_file(file_name):\n",
    "    file = open(file_name + \".txt\")\n",
    "    file_items = {}\n",
    "    item = \"\"\n",
    "    for line in file:\n",
    "        if line[0] == \">\":\n",
    "            ID = line.strip(\"\\n\")\n",
    "            file_items[ID] = \"\"\n",
    "        else:\n",
    "            file_items[ID] +=line.strip(\"\\n\")\n",
    "        \n",
    "    return file_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCSM - Finding a Shared Motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTGGGTAGAGTTGGTCTAGCGGAAAATAAATCGAGTCACGAGACCGATAAGTCTTGACGCCGGGGGAACCCACTCCCGAGTA\n"
     ]
    }
   ],
   "source": [
    "motifs = open_FASTA_file(\"sample\")\n",
    "motifs = list(motifs.values())\n",
    "\n",
    "def shortest_motif(motifs):\n",
    "    shortest_motif_length = min(list(map(len, motifs)))\n",
    "    for motif in motifs:\n",
    "        if len(motif) == shortest_motif_length:\n",
    "            return motif       \n",
    "\n",
    "def create_frames(reference, size):\n",
    "    frames = []\n",
    "    for frame in range(len(reference)):\n",
    "        if frame + size <= len(reference):\n",
    "            frames.append(reference[frame:frame+size])\n",
    "    frames = list(set(frames))\n",
    "\n",
    "    return frames\n",
    "\n",
    "def find_longest_common_substring(motifs, size):\n",
    "    if size > 0:\n",
    "        reference_motif = shortest_motif(motifs=motifs)\n",
    "        frames = create_frames(reference_motif, size)\n",
    "\n",
    "        for frame in frames:\n",
    "            is_substring = []\n",
    "            for motif in motifs:\n",
    "                is_substring.append(motif.find(frame))\n",
    "            \n",
    "            if -1 not in is_substring:\n",
    "                return frame\n",
    "        \n",
    "        return find_longest_common_substring(motifs, size-1)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "#size = len(shortest_motif(motifs))\n",
    "#print(find_longest_common_substring(motifs, size=size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REVP - Locating Restriction Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 4\n",
      "502 4\n",
      "839 4\n",
      "275 4\n",
      "663 4\n",
      "701 4\n",
      "911 4\n",
      "152 4\n",
      "796 4\n",
      "177 4\n",
      "230 4\n",
      "833 4\n",
      "872 4\n",
      "700 4\n",
      "93 4\n",
      "504 4\n",
      "252 4\n",
      "294 4\n",
      "456 4\n",
      "257 4\n",
      "378 4\n",
      "451 4\n",
      "595 4\n",
      "670 4\n",
      "846 4\n",
      "26 4\n",
      "147 4\n",
      "482 4\n",
      "627 4\n",
      "235 4\n",
      "370 4\n",
      "437 4\n",
      "444 4\n",
      "591 4\n",
      "756 4\n",
      "866 4\n",
      "105 4\n",
      "527 4\n",
      "737 4\n",
      "764 4\n",
      "1 4\n",
      "164 4\n",
      "357 4\n",
      "409 4\n",
      "411 4\n",
      "645 4\n",
      "827 4\n",
      "154 4\n",
      "215 4\n",
      "583 4\n",
      "57 4\n",
      "358 4\n",
      "410 4\n",
      "515 4\n",
      "644 4\n",
      "767 4\n",
      "455 6\n",
      "669 6\n",
      "436 6\n",
      "104 6\n",
      "845 6\n",
      "626 6\n",
      "755 6\n",
      "251 6\n",
      "293 6\n",
      "763 6\n",
      "409 6\n",
      "871 6\n",
      "454 8\n",
      "668 8\n",
      "435 8\n",
      "453 10\n",
      "667 10\n",
      "452 12\n"
     ]
    }
   ],
   "source": [
    "def find_complimentary_DNA(template):\n",
    "    forward = \"ATGC\"\n",
    "    reverse = \"TACG\"\n",
    "    table = template.maketrans(forward, reverse)\n",
    "\n",
    "    return template.translate(table)\n",
    "\n",
    "def is_palindrome(sequence):\n",
    "    return sequence[::-1] == find_complimentary_DNA(sequence)\n",
    "\n",
    "def find_palindromes(size):\n",
    "    products = list(product(\"ATGC\", repeat=size))\n",
    "    products = [\"\".join(item) for item in products]\n",
    "    palindromes = [DNA for DNA in products if DNA[::-1] == find_complimentary_DNA(DNA)]\n",
    "    \n",
    "    return palindromes\n",
    "\n",
    "def create_palindromes (start_size, end_size):\n",
    "    palindromes = []\n",
    "    for size in range(start_size, end_size+1, 2):\n",
    "        palindromes += find_palindromes(size)\n",
    "\n",
    "    return palindromes\n",
    "\n",
    "def save_palindromes_to_txt(palindromes):\n",
    "    palindromes = \",\".join(palindromes)\n",
    "    file = open(\"palindromes.txt\", \"w\")\n",
    "    file.write(palindromes)\n",
    "    file.close()\n",
    "\n",
    "#save_palindromes_to_txt(create_palindromes(4, 12))\n",
    "\n",
    "def load_palindromes(file_name):\n",
    "    file = open(file_name + \".txt\")\n",
    "    file = file.read()\n",
    "    palindromes = file.split(\",\")\n",
    "\n",
    "    return palindromes\n",
    "\n",
    "def find_restriction_sites(sequence, restriction_sites):\n",
    "    for site in restriction_sites:\n",
    "        location = sequence.find(site)\n",
    "        while location != -1:\n",
    "            print(location+1, len(site))\n",
    "            location = sequence.find(site, location+1)\n",
    "\n",
    "#palindromes = load_palindromes(\"palindromes\")\n",
    "#sequence = open_FASTA_file(\"rosalind_revp\")\n",
    "#sequence = list(sequence.values())[0]\n",
    "#find_restriction_sites(sequence=sequence, restriction_sites=palindromes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRTM - Calculating Protein Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'71.03711'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_table_file = r\"C:\\Users\\vente\\OneDrive\\Documents\\Code\\bioinformatics_challenges\\databases\\monoisotopic_mass_table_amino_acids.txt\"\n",
    "mass_table_file = list(map(lambda x: x.split(), open(mass_table_file).read().split(\"\\n\")))\n",
    "\n",
    "mass_table = {}\n",
    "map(lambda x: mass_table.update({x[0]: x[1]}), mass_table_file)\n",
    "mass_table_file[0][1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "311724412226088b683ffffa8f56bd226d9eb83eedc73f5fb48200bda608b17b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
